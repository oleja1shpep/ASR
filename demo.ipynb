{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone repo"
      ],
      "metadata": {
        "id": "KEDkR2Ywzqtw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srHnAAgys8zo",
        "outputId": "f76a1dac-88f7-4b6f-864e-9b1a3c378470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ASR'...\n",
            "remote: Enumerating objects: 374, done.\u001b[K\n",
            "remote: Counting objects: 100% (374/374), done.\u001b[K\n",
            "remote: Compressing objects: 100% (258/258), done.\u001b[K\n",
            "remote: Total 374 (delta 203), reused 276 (delta 105), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (374/374), 79.80 KiB | 1.27 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/oleja1shpep/ASR.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "id": "3_eVJMkozuZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ASR/requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXf4mk9PuXMl",
        "outputId": "1447fb31-f393-4c8d-b11d-d2307afd0aaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[32m/\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.4/755.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.5/766.5 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.0/221.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download checkpoints"
      ],
      "metadata": {
        "id": "LFH_tpLmzyBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e -O model_best.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJnRIWrAswQZ",
        "outputId": "8dcb81ef-98fb-492e-e4c4-767e7f3e6023"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e\n",
            "From (redirected): https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e&confirm=t&uuid=e365b112-01a8-4395-be1d-580f160a5b56\n",
            "To: /content/model_best.pth\n",
            "100% 221M/221M [00:04<00:00, 48.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on src datasets"
      ],
      "metadata": {
        "id": "XQ8urb_Yz7uM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically the commands looks like:\n",
        "\n",
        "```\n",
        "!python ASR/inference.py inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "inferencer.save_preds_path=\"predictions\"  \\\n",
        "datasets.dataset._target_=\"src.datasets.<name>\" \\\n",
        "datasets.dataset.part=\"<part>\" datasets.dataset.arg1=\"...\"\n",
        "```\n",
        "\n",
        "The predictions will be saved to predictions/dataset folder\n",
        "\n",
        "If you want to save targets to the directory just add inferencer.save_targets_path arguement to command\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "6Q6ItCBc8O3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preds will be stored in predictions/dataset folder, targets will be stored in targets/dataset folder\n",
        "\n",
        "!python ASR/inference.py inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "inferencer.save_preds_path=\"predictions\" \\\n",
        "inferencer.save_targets_path=\"targets\" \\\n",
        "datasets.dataset._target_=\"src.datasets.LibrispeechDataset\" \\\n",
        "datasets.dataset.part=\"test-clean\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV1WgIINuaAB",
        "outputId": "9b325bd2-b0e9-4a51-c616-c9d0c11557a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16 19:51:15,603][torchaudio.utils.download][INFO] - Downloading decoder-assets/librispeech-3-gram/lexicon.txt to /root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt\n",
            "\r  0% 0.00/4.97M [00:00<?, ?B/s]\r100% 4.97M/4.97M [00:00<00:00, 91.6MB/s]\n",
            "[2025-10-16 19:51:15,734][torchaudio.utils.download][INFO] - Downloading decoder-assets/librispeech-3-gram/tokens.txt to /root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt\n",
            "100% 57.0/57.0 [00:00<00:00, 179kB/s]\n",
            "[2025-10-16 19:51:15,776][torchaudio.utils.download][INFO] - Downloading decoder-assets/librispeech-3-gram/lm.bin to /root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin\n",
            "100% 1.69G/1.69G [00:08<00:00, 206MB/s]\n",
            "Loading part test-clean\n",
            "Preparing librispeech folders: test-clean: 100% 87/87 [00:08<00:00, 10.02it/s]\n",
            "Conformer(\n",
            "  (conv_subsampling): Conv1dSubsampling(\n",
            "    (layers): Sequential(\n",
            "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(3,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (conformer_blocks): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (ffn1): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attention): MultiHeadAttention(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RoPEMultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (rope_q): RoPE()\n",
            "          (rope_k): RoPE()\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (conv): ConvModule(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (layers): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): GLU(dim=1)\n",
            "          (2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
            "          (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): SwishActivation()\n",
            "          (5): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "          (6): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ffn2): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=29, bias=False)\n",
            ")\n",
            "All parameters: 18394752\n",
            "Trainable parameters: 18394752\n",
            "Loading model weights from: ./model_best.pth ...\n",
            "dataset: 100% 262/262 [02:14<00:00,  1.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calc metrics on src datasets\n",
        "\n",
        "to calc metrics you need targets directory path, so you'd better add inferencer.save_targets_path arguement to the script above"
      ],
      "metadata": {
        "id": "EvNGN5Mognx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ASR/calc_metrics.py target_dir=\"targets/dataset\" predictions_dir=\"predictions/dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN5jwhrfhRVb",
        "outputId": "b9eebe27-687e-477f-f9b6-5de913427c94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16 19:54:27,317][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 19:54:27,318][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 19:54:27,318][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "    CER_(Beam_Search): 0.06156893533399329\n",
            "    WER_(Beam_Search): 0.13798817778374514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on custom dataset"
      ],
      "metadata": {
        "id": "881ICvc201I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download some dataset\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
        "!unzip sanity_test_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzbEz7a1m8u",
        "outputId": "94d7f2b1-8bdb-4ae5-b47b-ee7c1fcc8073"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
            "To: /content/sanity_test_data.zip\n",
            "\r  0% 0.00/747k [00:00<?, ?B/s]\r100% 747k/747k [00:00<00:00, 7.92MB/s]\n",
            "Archive:  sanity_test_data.zip\n",
            "   creating: test_data/\n",
            "   creating: test_data/audio/\n",
            "  inflating: test_data/audio/84-121550-0000.flac  \n",
            "  inflating: test_data/audio/84-121550-0001.flac  \n",
            "  inflating: test_data/audio/84-121550-0002.flac  \n",
            "  inflating: test_data/audio/84-121550-0003.flac  \n",
            "  inflating: test_data/audio/84-121550-0004.flac  \n",
            "   creating: test_data/transcriptions/\n",
            "  inflating: test_data/transcriptions/84-121550-0000.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0001.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0002.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0003.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0004.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate the transcriptions absence\n",
        "# !rm -rf ./test_data/transcriptions"
      ],
      "metadata": {
        "id": "GvOLF7t2XP89"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically the command template looks like this:\n",
        "\n",
        "\n",
        "```\n",
        "!python ASR/inference.py -cn=inference_custom \\\n",
        "inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "datasets.custom.data_dir=\"<path_to_dataset>\" \\\n",
        "inferencer.save_preds_path=\"predictions\" \\\n",
        "inferencer.save_targets_path=\"targets\" \\ # optional\n",
        "```\n",
        "\n",
        "The argument inferencer.save_targets_path is optional cause you already have your transcriptions in folder \\<path_to_dataset\\>/transcriptions"
      ],
      "metadata": {
        "id": "W_r_NwfHkbT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preds will be stored in predictions/custom folder, targets will be stored in targets/custom folder\n",
        "\n",
        "!python ASR/inference.py -cn=inference_custom inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "datasets.custom.data_dir=\"test_data\" \\\n",
        "inferencer.save_preds_path=\"predictions\" \\\n",
        "inferencer.save_targets_path=\"targets\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qONEu8fcj9YG",
        "outputId": "a6ff7d77-1baf-49ea-a200-680cc9621b91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16 19:54:47,988][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 19:54:47,989][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 19:54:47,989][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "Conformer(\n",
            "  (conv_subsampling): Conv1dSubsampling(\n",
            "    (layers): Sequential(\n",
            "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(3,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (conformer_blocks): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (ffn1): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attention): MultiHeadAttention(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RoPEMultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (rope_q): RoPE()\n",
            "          (rope_k): RoPE()\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (conv): ConvModule(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (layers): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): GLU(dim=1)\n",
            "          (2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
            "          (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): SwishActivation()\n",
            "          (5): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "          (6): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ffn2): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=29, bias=False)\n",
            ")\n",
            "All parameters: 18394752\n",
            "Trainable parameters: 18394752\n",
            "Loading model weights from: ./model_best.pth ...\n",
            "custom: 100% 5/5 [00:00<00:00,  6.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate metrics on custom data"
      ],
      "metadata": {
        "id": "p0aT1RfB2blh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do not forget to add 'custom' to the end of predictions_dir\n",
        "!python ASR/calc_metrics.py target_dir=\"targets/custom\" predictions_dir=\"predictions/custom\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fktKli1J2T2I",
        "outputId": "9813b343-1852-433d-a4ca-6e2ac2a7b7f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16 19:55:00,258][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 19:55:00,258][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 19:55:00,258][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "    CER_(Beam_Search): 0.025568753142282553\n",
            "    WER_(Beam_Search): 0.054296066252587996\n"
          ]
        }
      ]
    }
  ]
}
