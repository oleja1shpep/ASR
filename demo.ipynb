{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone repo"
      ],
      "metadata": {
        "id": "KEDkR2Ywzqtw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srHnAAgys8zo",
        "outputId": "25a59dfb-c40a-428c-d3cd-bc1337a42532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ASR'...\n",
            "remote: Enumerating objects: 350, done.\u001b[K\n",
            "remote: Counting objects: 100% (350/350), done.\u001b[K\n",
            "remote: Compressing objects: 100% (236/236), done.\u001b[K\n",
            "remote: Total 350 (delta 182), reused 271 (delta 103), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (350/350), 75.44 KiB | 10.78 MiB/s, done.\n",
            "Resolving deltas: 100% (182/182), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/oleja1shpep/ASR.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "id": "3_eVJMkozuZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ASR/requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXf4mk9PuXMl",
        "outputId": "a50d5a3b-460f-4d7b-dcdb-095c989b99fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[32m-\u001b[0m \u001b[32m0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[33m0:00:00\u001b[0m\r\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m245.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\r\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.4/755.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.5/766.5 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.0/221.0 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download checkpoints"
      ],
      "metadata": {
        "id": "LFH_tpLmzyBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e -O model_best.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJnRIWrAswQZ",
        "outputId": "2e2febd0-1352-4526-ca8b-0e80b05790b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e\n",
            "From (redirected): https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e&confirm=t&uuid=6250eca8-7d47-4ee2-a712-fa64f730fa52\n",
            "To: /content/model_best.pth\n",
            "100% 221M/221M [00:05<00:00, 44.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on src datasets"
      ],
      "metadata": {
        "id": "XQ8urb_Yz7uM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically the commands looks like:\n",
        "\n",
        "```\n",
        "!python ASR/inference.py inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "datasets.dataset._target_=\"src.datasets.<name>\" datasets.dataset.arg1=\"...\"\n",
        "```\n",
        "\n",
        "Example"
      ],
      "metadata": {
        "id": "6Q6ItCBc8O3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ASR/inference.py inferencer.from_pretrained=\"./model_best.pth\" datasets.dataset._target_=\"src.datasets.LibrispeechDataset\" \\\n",
        "datasets.dataset.part=\"test-clean\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV1WgIINuaAB",
        "outputId": "7a3bd681-60f5-4b51-b460-67ff76626627"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16 17:13:20,987][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 17:13:20,987][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 17:13:20,988][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "Loading part test-clean\n",
            "Preparing librispeech folders: test-clean: 100% 87/87 [00:08<00:00, 10.83it/s]\n",
            "Conformer(\n",
            "  (conv_subsampling): Conv1dSubsampling(\n",
            "    (layers): Sequential(\n",
            "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(3,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (conformer_blocks): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (ffn1): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attention): MultiHeadAttention(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RoPEMultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (rope_q): RoPE()\n",
            "          (rope_k): RoPE()\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (conv): ConvModule(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (layers): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): GLU(dim=1)\n",
            "          (2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
            "          (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): SwishActivation()\n",
            "          (5): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "          (6): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ffn2): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=29, bias=False)\n",
            ")\n",
            "All parameters: 18394752\n",
            "Trainable parameters: 18394752\n",
            "Loading model weights from: ./model_best.pth ...\n",
            "dataset: 100% 262/262 [03:35<00:00,  1.22it/s]\n",
            "    dataset_CER_(Beam_Search): 0.0615610806769271\n",
            "    dataset_WER_(Beam_Search): 0.1380115278786602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on custom dataset"
      ],
      "metadata": {
        "id": "881ICvc201I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
        "!unzip sanity_test_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzbEz7a1m8u",
        "outputId": "959098ae-ad83-4a83-c3a4-e1bd658dcca1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
            "To: /content/sanity_test_data.zip\n",
            "\r  0% 0.00/747k [00:00<?, ?B/s]\r100% 747k/747k [00:00<00:00, 46.8MB/s]\n",
            "Archive:  sanity_test_data.zip\n",
            "   creating: test_data/\n",
            "   creating: test_data/audio/\n",
            "  inflating: test_data/audio/84-121550-0000.flac  \n",
            "  inflating: test_data/audio/84-121550-0001.flac  \n",
            "  inflating: test_data/audio/84-121550-0002.flac  \n",
            "  inflating: test_data/audio/84-121550-0003.flac  \n",
            "  inflating: test_data/audio/84-121550-0004.flac  \n",
            "   creating: test_data/transcriptions/\n",
            "  inflating: test_data/transcriptions/84-121550-0000.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0001.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0002.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0003.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0004.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the script saves predictions in folder <inferencer.save_path>/custom/\n",
        "!python ASR/inference.py -cn=inference_custom inferencer.from_pretrained=\"./model_best.pth\" datasets.custom.data_dir=\"test_data\" inferencer.save_path='predictions'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFVh2VcD031b",
        "outputId": "307bdaba-bb1c-47ed-dd3c-2f92e3bd38cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16 17:19:08,566][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 17:19:08,567][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 17:19:08,567][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "Conformer(\n",
            "  (conv_subsampling): Conv1dSubsampling(\n",
            "    (layers): Sequential(\n",
            "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(3,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (conformer_blocks): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (ffn1): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attention): MultiHeadAttention(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RoPEMultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (rope_q): RoPE()\n",
            "          (rope_k): RoPE()\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (conv): ConvModule(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (layers): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): GLU(dim=1)\n",
            "          (2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
            "          (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): SwishActivation()\n",
            "          (5): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "          (6): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ffn2): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=29, bias=False)\n",
            ")\n",
            "All parameters: 18394752\n",
            "Trainable parameters: 18394752\n",
            "Loading model weights from: ./model_best.pth ...\n",
            "custom: 100% 5/5 [00:00<00:00,  5.25it/s]\n",
            "    custom_CER_(Beam_Search): 0.025568753142282553\n",
            "    custom_WER_(Beam_Search): 0.054296066252587996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate metrics"
      ],
      "metadata": {
        "id": "p0aT1RfB2blh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do not forget to add 'custom' to the end of predictions_dir\n",
        "!python ASR/calc_metrics.py target_dir=\"test_data/transcriptions\" predictions_dir=\"predictions/custom\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fktKli1J2T2I",
        "outputId": "0eeacd08-e939-4296-c322-6bd4ac704c4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16 17:19:19,119][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 17:19:19,119][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 17:19:19,119][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "    CER_(Beam_Search): 0.025568753142282553\n",
            "    WER_(Beam_Search): 0.054296066252587996\n"
          ]
        }
      ]
    }
  ]
}
