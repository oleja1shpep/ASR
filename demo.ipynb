{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEDkR2Ywzqtw"
      },
      "source": [
        "# Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srHnAAgys8zo"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/oleja1shpep/ASR.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_eVJMkozuZe"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXf4mk9PuXMl",
        "outputId": "0f403def-2d36-4bb3-f4e8-0b7c442b4e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ASR/requirements.txt -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFH_tpLmzyBl"
      },
      "source": [
        "# Download checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJnRIWrAswQZ",
        "outputId": "3d30ada6-9d16-4a53-f1e3-9ba1adfec54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18NkqGrdo5GEPKDfBSRvbInnYG2kPDskY\n",
            "From (redirected): https://drive.google.com/uc?id=18NkqGrdo5GEPKDfBSRvbInnYG2kPDskY&confirm=t&uuid=1037d6b4-cc4a-440e-a3f0-955b8ccacaeb\n",
            "To: /content/model_best.pth\n",
            "100% 221M/221M [00:05<00:00, 43.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=18NkqGrdo5GEPKDfBSRvbInnYG2kPDskY -O model_best.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ8urb_Yz7uM"
      },
      "source": [
        "# Run inference on src datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q6ItCBc8O3y"
      },
      "source": [
        "Basically the commands looks like:\n",
        "\n",
        "```\n",
        "!python ASR/inference.py inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "inferencer.save_preds_path=\"predictions\"  \\\n",
        "datasets.dataset._target_=\"src.datasets.<name>\" \\\n",
        "datasets.dataset.part=\"<part>\" datasets.dataset.arg1=\"...\"\n",
        "```\n",
        "\n",
        "The predictions will be saved to predictions/dataset folder\n",
        "\n",
        "If you want to save targets to the directory just add inferencer.save_targets_path arguement to command\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV1WgIINuaAB",
        "outputId": "a7e14b88-3984-44fe-c8e7-da8d6055dca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-10-16 20:22:31,107][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 20:22:31,108][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 20:22:31,108][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "Conformer(\n",
            "  (conv_subsampling): Conv1dSubsampling(\n",
            "    (layers): Sequential(\n",
            "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(3,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (conformer_blocks): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (ffn1): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attention): MultiHeadAttention(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RoPEMultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (rope_q): RoPE()\n",
            "          (rope_k): RoPE()\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (conv): ConvModule(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (layers): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): GLU(dim=1)\n",
            "          (2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
            "          (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): SwishActivation()\n",
            "          (5): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "          (6): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ffn2): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=29, bias=False)\n",
            ")\n",
            "All parameters: 18394752\n",
            "Trainable parameters: 18394752\n",
            "Loading model weights from: ./model_best.pth ...\n",
            "dataset: 100% 262/262 [02:13<00:00,  1.96it/s]\n"
          ]
        }
      ],
      "source": [
        "# preds will be stored in predictions/dataset folder, targets will be stored in targets/dataset folder\n",
        "\n",
        "!python ASR/inference.py inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "inferencer.save_preds_path=\"predictions\" \\\n",
        "inferencer.save_targets_path=\"targets\" \\\n",
        "datasets.dataset._target_=\"src.datasets.LibrispeechDataset\" \\\n",
        "datasets.dataset.part=\"test-clean\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvNGN5Mognx8"
      },
      "source": [
        "# Calc metrics on src datasets\n",
        "\n",
        "to calc metrics you need targets directory path, so you'd better add inferencer.save_targets_path arguement to the script above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN5jwhrfhRVb",
        "outputId": "c1cb65c6-9b4f-47c1-99c3-35cedb40c669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-10-16 20:24:55,102][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-16 20:24:55,102][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-16 20:24:55,102][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "    CER_(Beam_Search): 0.06525026260966799\n",
            "    WER_(Beam_Search): 0.14263695438547502\n"
          ]
        }
      ],
      "source": [
        "!python ASR/calc_metrics.py target_dir=\"targets/dataset\" predictions_dir=\"predictions/dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "881ICvc201I7"
      },
      "source": [
        "# Run inference on custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7qzbEz7a1m8u",
        "outputId": "e5a9b981-4aab-41fa-bce8-aed22f3a14dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
            "To: /content/sanity_test_data.zip\n",
            "\r  0% 0.00/747k [00:00<?, ?B/s]\r100% 747k/747k [00:00<00:00, 51.0MB/s]\n",
            "Archive:  sanity_test_data.zip\n",
            "   creating: test_data/\n",
            "   creating: test_data/audio/\n",
            "  inflating: test_data/audio/84-121550-0000.flac  \n",
            "  inflating: test_data/audio/84-121550-0001.flac  \n",
            "  inflating: test_data/audio/84-121550-0002.flac  \n",
            "  inflating: test_data/audio/84-121550-0003.flac  \n",
            "  inflating: test_data/audio/84-121550-0004.flac  \n",
            "   creating: test_data/transcriptions/\n",
            "  inflating: test_data/transcriptions/84-121550-0000.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0001.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0002.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0003.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0004.txt  \n"
          ]
        }
      ],
      "source": [
        "# download some dataset\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
        "!unzip sanity_test_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GvOLF7t2XP89"
      },
      "outputs": [],
      "source": [
        "# simulate the transcriptions absence\n",
        "# !rm -rf ./test_data/transcriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_r_NwfHkbT1"
      },
      "source": [
        "Basically the command template looks like this:\n",
        "\n",
        "\n",
        "```\n",
        "!python ASR/inference.py -cn=inference_custom \\\n",
        "inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "datasets.custom.data_dir=\"<path_to_dataset>\" \\\n",
        "inferencer.save_preds_path=\"predictions\" \\\n",
        "inferencer.save_targets_path=\"targets\" \\ # optional\n",
        "```\n",
        "\n",
        "The argument inferencer.save_targets_path is optional cause you already have your transcriptions in folder \\<path_to_dataset\\>/transcriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qONEu8fcj9YG"
      },
      "outputs": [],
      "source": [
        "# preds will be stored in predictions/custom folder, targets will be stored in targets/custom folder\n",
        "\n",
        "!python ASR/inference.py -cn=inference_custom inferencer.from_pretrained=\"./model_best.pth\" \\\n",
        "datasets.custom.data_dir=\"test_data\" \\\n",
        "inferencer.save_preds_path=\"predictions\" \\\n",
        "inferencer.save_targets_path=\"targets\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0aT1RfB2blh"
      },
      "source": [
        "# Calculate metrics on custom data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fktKli1J2T2I"
      },
      "outputs": [],
      "source": [
        "# do not forget to add 'custom' to the end of predictions_dir\n",
        "!python ASR/calc_metrics.py target_dir=\"targets/custom\" predictions_dir=\"predictions/custom\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
