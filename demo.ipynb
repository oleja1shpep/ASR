{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone repo"
      ],
      "metadata": {
        "id": "KEDkR2Ywzqtw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srHnAAgys8zo",
        "outputId": "3ebe2048-7d3f-4319-8496-96d1c67cf476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ASR'...\n",
            "remote: Enumerating objects: 315, done.\u001b[K\n",
            "remote: Counting objects: 100% (315/315), done.\u001b[K\n",
            "remote: Compressing objects: 100% (214/214), done.\u001b[K\n",
            "remote: Total 315 (delta 156), reused 249 (delta 90), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (315/315), 69.15 KiB | 4.61 MiB/s, done.\n",
            "Resolving deltas: 100% (156/156), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/oleja1shpep/ASR.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "id": "3_eVJMkozuZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ASR/requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXf4mk9PuXMl",
        "outputId": "41408fb8-aa7d-45b5-ce8e-f09cae538425"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[32m-\u001b[0m \u001b[32m0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[33m0:00:00\u001b[0m\r\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m251.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\r\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m272.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\r\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\r\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.4/755.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.5/766.5 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.0/221.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download checkpoints"
      ],
      "metadata": {
        "id": "LFH_tpLmzyBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e -O model_best.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJnRIWrAswQZ",
        "outputId": "19217733-c260-4f15-8662-6992c744f6d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e\n",
            "From (redirected): https://drive.google.com/uc?id=1LVKpi6Nu7Rk8FcNs88paNXbCqe52kl7e&confirm=t&uuid=086555a2-1651-427c-8a99-8897df0cb887\n",
            "To: /content/model_best.pth\n",
            "100% 221M/221M [00:01<00:00, 137MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on test-clean and test-other"
      ],
      "metadata": {
        "id": "XQ8urb_Yz7uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ASR/inference.py inferencer.from_pretrained=\"./model_best.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV1WgIINuaAB",
        "outputId": "0d3f7f2a-c4ef-4db7-cf33-6c3b9f2996eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-15 17:59:57,131][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-15 17:59:57,131][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-15 17:59:57,131][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "Loading part test-other\n",
            "Preparing librispeech folders: test-other: 100% 90/90 [00:07<00:00, 12.09it/s]\n",
            "Loading part test-clean\n",
            "Preparing librispeech folders: test-clean: 100% 87/87 [00:07<00:00, 11.48it/s]\n",
            "Conformer(\n",
            "  (conv_subsampling): Conv1dSubsampling(\n",
            "    (layers): Sequential(\n",
            "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(3,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (conformer_blocks): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (ffn1): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attention): MultiHeadAttention(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RoPEMultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (rope_q): RoPE()\n",
            "          (rope_k): RoPE()\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (conv): ConvModule(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (layers): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): GLU(dim=1)\n",
            "          (2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
            "          (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): SwishActivation()\n",
            "          (5): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "          (6): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ffn2): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=29, bias=False)\n",
            ")\n",
            "All parameters: 18394752\n",
            "Trainable parameters: 18394752\n",
            "Loading model weights from: ./model_best.pth ...\n",
            "test-other: 100% 294/294 [03:28<00:00,  1.41it/s]\n",
            "test-clean: 100% 262/262 [03:26<00:00,  1.27it/s]\n",
            "    test-other_CER_(Beam_Search): 0.2012465381443528\n",
            "    test-other_WER_(Beam_Search): 0.3727621210794829\n",
            "    test-clean_CER_(Beam_Search): 0.06156297159353525\n",
            "    test-clean_WER_(Beam_Search): 0.1379556915394269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on custom dataset"
      ],
      "metadata": {
        "id": "881ICvc201I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
        "!unzip sanity_test_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzbEz7a1m8u",
        "outputId": "d39b9f00-31ba-4a2f-ccd8-db0f065cf2a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s2f_IhxJUV7RxmExwx_rCvvPSSG81nMi\n",
            "To: /content/sanity_test_data.zip\n",
            "\r  0% 0.00/747k [00:00<?, ?B/s]\r100% 747k/747k [00:00<00:00, 112MB/s]\n",
            "Archive:  sanity_test_data.zip\n",
            "   creating: test_data/\n",
            "   creating: test_data/audio/\n",
            "  inflating: test_data/audio/84-121550-0000.flac  \n",
            "  inflating: test_data/audio/84-121550-0001.flac  \n",
            "  inflating: test_data/audio/84-121550-0002.flac  \n",
            "  inflating: test_data/audio/84-121550-0003.flac  \n",
            "  inflating: test_data/audio/84-121550-0004.flac  \n",
            "   creating: test_data/transcriptions/\n",
            "  inflating: test_data/transcriptions/84-121550-0000.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0001.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0002.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0003.txt  \n",
            "  inflating: test_data/transcriptions/84-121550-0004.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the script saves predictions in folder <inferencer.save_path>/custom/\n",
        "!python ASR/inference.py -cn=inference_custom inferencer.from_pretrained=\"./model_best.pth\" datasets.custom.data_dir=\"test_data\" inferencer.save_path='predictions'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFVh2VcD031b",
        "outputId": "0abe02bb-79d1-4b1f-9fa2-5e9f63f550ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-15 17:58:35,594][torchaudio.utils.download][INFO] - Downloading decoder-assets/librispeech-3-gram/lexicon.txt to /root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt\n",
            "100% 4.97M/4.97M [00:00<00:00, 68.3MB/s]\n",
            "[2025-10-15 17:58:35,748][torchaudio.utils.download][INFO] - Downloading decoder-assets/librispeech-3-gram/tokens.txt to /root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt\n",
            "100% 57.0/57.0 [00:00<00:00, 284kB/s]\n",
            "[2025-10-15 17:58:35,795][torchaudio.utils.download][INFO] - Downloading decoder-assets/librispeech-3-gram/lm.bin to /root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin\n",
            "100% 1.69G/1.69G [00:07<00:00, 234MB/s]\n",
            "Conformer(\n",
            "  (conv_subsampling): Conv1dSubsampling(\n",
            "    (layers): Sequential(\n",
            "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(3,), padding=(1,))\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (conformer_blocks): ModuleList(\n",
            "    (0-11): 12 x ConformerBlock(\n",
            "      (ffn1): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (attention): MultiHeadAttention(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention): RoPEMultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (rope_q): RoPE()\n",
            "          (rope_k): RoPE()\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (conv): ConvModule(\n",
            "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (layers): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): GLU(dim=1)\n",
            "          (2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)\n",
            "          (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): SwishActivation()\n",
            "          (5): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "          (6): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ffn2): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (2): SwishActivation()\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "          (4): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (5): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=29, bias=False)\n",
            ")\n",
            "All parameters: 18394752\n",
            "Trainable parameters: 18394752\n",
            "Loading model weights from: ./model_best.pth ...\n",
            "custom: 100% 5/5 [00:01<00:00,  3.57it/s]\n",
            "    custom_CER_(Beam_Search): 0.025568753142282553\n",
            "    custom_WER_(Beam_Search): 0.054296066252587996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate metrics"
      ],
      "metadata": {
        "id": "p0aT1RfB2blh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do not forget to add 'custom' to the end of predictions_dir\n",
        "!python ASR/calc_metrics.py target_dir=\"test_data/transcriptions\" predictions_dir=\"predictions/custom\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fktKli1J2T2I",
        "outputId": "3929abfd-639f-4f9b-bef4-f0f2ee28fdef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-15 17:58:55,638][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lexicon.txt) exists. Skipping the download.\n",
            "[2025-10-15 17:58:55,638][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/tokens.txt) exists. Skipping the download.\n",
            "[2025-10-15 17:58:55,639][torchaudio.utils.download][INFO] - The local file (/root/.cache/torch/hub/torchaudio/decoder-assets/librispeech-3-gram/lm.bin) exists. Skipping the download.\n",
            "    CER_(Beam_Search): 0.025568753142282553\n",
            "    WER_(Beam_Search): 0.054296066252587996\n"
          ]
        }
      ]
    }
  ]
}
